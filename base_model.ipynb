{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 78000 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Doing data augmantation in order to make the learning more difficult\n",
    "train_datagen=ImageDataGenerator(\n",
    "                                   rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True\n",
    "                                                        )\n",
    "\n",
    "#preprocessing the training set\n",
    "\n",
    "training_set= train_datagen.flow_from_directory('training set directory',\n",
    "                                                target_size=(32,32),\n",
    "                                                batch_size=32,\n",
    "                                                class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./255)\n",
    "test_set=test_datagen.flow_from_directory('test set directory',\n",
    "                                           target_size=(64,64),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1815 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "evaluation_set=ImageDataGenerator(rescale=1./255)\n",
    "evaluation_set=evaluation_set.flow_from_directory('evaluation set directory',\n",
    "                                           target_size=(32,32),\n",
    "                                           batch_size=32,\n",
    "                                           class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the cnn\n",
    "cnn=tf.keras.models.Sequential()\n",
    "\n",
    "#adding the first layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                              kernel_size=3,\n",
    "                              activation='relu',\n",
    "                              input_shape=[32,32,3]))\n",
    "#pooling\n",
    "cnn.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "#Second Layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n",
    "#Third Layer\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))\n",
    "cnn.add(tf.keras.layers.MaxPool2D(2,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting the 2-d pixel image matrix into 1-d image matrix for input layer of cnn\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Full Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combing all layers of CNN\n",
    "cnn.add(tf.keras.layers.Dense(units=128,activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining the output layer\n",
    "\n",
    "cnn.add(tf.keras.layers.Dense(units=26,activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#declairing the optimizer and loss for backprogation process\n",
    "cnn.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy',tf.keras.metrics.Precision(),tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2438/2438 [==============================] - 1486s 610ms/step - loss: 0.1107 - accuracy: 0.9614 - precision: 0.9663 - recall: 0.9576 - val_loss: 32.3368 - val_accuracy: 0.1058 - val_precision: 0.1078 - val_recall: 0.1058\n",
      "Epoch 2/5\n",
      "2438/2438 [==============================] - 1247s 512ms/step - loss: 0.0948 - accuracy: 0.9673 - precision: 0.9708 - recall: 0.9644 - val_loss: 34.5739 - val_accuracy: 0.1240 - val_precision: 0.1248 - val_recall: 0.1234\n",
      "Epoch 3/5\n",
      "2438/2438 [==============================] - 582s 239ms/step - loss: 0.0874 - accuracy: 0.9699 - precision: 0.9725 - recall: 0.9675 - val_loss: 42.0535 - val_accuracy: 0.0909 - val_precision: 0.0923 - val_recall: 0.0909\n",
      "Epoch 4/5\n",
      "2438/2438 [==============================] - 172s 71ms/step - loss: 0.0775 - accuracy: 0.9739 - precision: 0.9759 - recall: 0.9720 - val_loss: 41.6831 - val_accuracy: 0.0843 - val_precision: 0.0847 - val_recall: 0.0837\n",
      "Epoch 5/5\n",
      "2438/2438 [==============================] - 196s 80ms/step - loss: 0.0674 - accuracy: 0.9774 - precision: 0.9791 - recall: 0.9759 - val_loss: 37.8966 - val_accuracy: 0.0837 - val_precision: 0.0843 - val_recall: 0.0832\n"
     ]
    }
   ],
   "source": [
    "\n",
    "cnn.fit(x = training_set,validation_data = evaluation_set, epochs = 5)\n",
    "\n",
    "#Saving the model\n",
    "cnn.save('my_model.h5') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing Class of each image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25}\n",
      "{0: 'a', 1: 'b', 2: 'c', 3: 'd', 4: 'e', 5: 'f', 6: 'g', 7: 'h', 8: 'i', 9: 'j', 10: 'k', 11: 'l', 12: 'm', 13: 'n', 14: 'o', 15: 'p', 16: 'q', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'v', 22: 'w', 23: 'x', 24: 'y', 25: 'z'}\n",
      "57/57 [==============================] - 5s 78ms/step - loss: 37.8966 - accuracy: 0.0837 - precision: 0.0843 - recall: 0.0832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[37.8966064453125,\n",
       " 0.08374655991792679,\n",
       " 0.08431044220924377,\n",
       " 0.08319558948278427]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names=training_set.class_indices\n",
    "\n",
    "#loading the saved model\n",
    "n_cnn=tf.keras.models.load_model('my_model.h5')\n",
    "print(class_names)\n",
    "d={}\n",
    "k=0\n",
    "l=['a','b','c','d','e','f','g','h','i','j','k','l','m','n','o','p','q','r','s','t','u','v','w','x','y','z']\n",
    "for i in range(0,26):\n",
    "    d[i]=l[k]\n",
    "    k+=1\n",
    "print(d)\n",
    "\n",
    "\n",
    "n_cnn.evaluate(evaluation_set)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making a single Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This image most likely belongs to z with a 98.07 percent confidence.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image=image.load_img('test_image_directory_for_testing/test.jpg',target_size=(32,32))\n",
    "\n",
    "#converting image into 2d arrray as cnn takes array as input\n",
    "test_image=image.img_to_array(test_image)\n",
    "test_image=np.expand_dims(test_image,axis=0)\n",
    "\n",
    "result=(n_cnn.predict(test_image))\n",
    "score = tf.nn.softmax(result[0])\n",
    "print(\n",
    "    \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n",
    "    .format(d[np.argmax(score)], 1000 * np.max(score))\n",
    ")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9f56aff3138895671670a9ebb5f46fd2cca584a94dffdd1797f9eaa217be318b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
